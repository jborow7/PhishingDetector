{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sMnEbmPFWvci",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMnEbmPFWvci",
        "outputId": "a029a87a-8e7e-43c4-87e3-c8e82a5ce1b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: transformers 4.52.4\n",
            "Uninstalling transformers-4.52.4:\n",
            "  Successfully uninstalled transformers-4.52.4\n",
            "Found existing installation: peft 0.15.2\n",
            "Uninstalling peft-0.15.2:\n",
            "  Successfully uninstalled peft-0.15.2\n"
          ]
        }
      ],
      "source": [
        "pip uninstall -y transformers peft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "I4HzJDnaWyB3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4HzJDnaWyB3",
        "outputId": "f38c2650-2b3f-4d46-98b4-a5febdbacff9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.37.2\n",
            "  Downloading transformers-4.37.2-py3-none-any.whl.metadata (129 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/129.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting peft==0.10.0\n",
            "  Downloading peft-0.10.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2) (0.33.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2) (2.32.3)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers==4.37.2)\n",
            "  Downloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (1.8.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.2) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.2) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.2) (1.1.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13.0->peft==0.10.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.10.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft==0.10.0) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.37.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.37.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.37.2) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.37.2) (2025.6.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft==0.10.0) (3.0.2)\n",
            "Downloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.10.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m100.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m122.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m96.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, tokenizers, nvidia-cusolver-cu12, transformers, peft\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.2\n",
            "    Uninstalling tokenizers-0.21.2:\n",
            "      Successfully uninstalled tokenizers-0.21.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.37.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 peft-0.10.0 tokenizers-0.15.2 transformers-4.37.2\n"
          ]
        }
      ],
      "source": [
        "pip install transformers==4.37.2 peft==0.10.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EzUWqyBhWzfN",
      "metadata": {
        "id": "EzUWqyBhWzfN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0f06184-2393-470e-fc70-c8b5f41ec5bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate==0.27.2\n",
            "  Downloading accelerate-0.27.2-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.27.2) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.27.2) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.27.2) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==0.27.2) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.27.2) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from accelerate==0.27.2) (0.33.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.27.2) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate==0.27.2) (1.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->accelerate==0.27.2) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->accelerate==0.27.2) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->accelerate==0.27.2) (1.1.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.27.2) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.27.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.27.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.27.2) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.27.2) (2025.6.15)\n",
            "Downloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: accelerate\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.8.1\n",
            "    Uninstalling accelerate-1.8.1:\n",
            "      Successfully uninstalled accelerate-1.8.1\n",
            "Successfully installed accelerate-0.27.2\n"
          ]
        }
      ],
      "source": [
        "pip install accelerate==0.27.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "y8FTiXW5W1ax",
      "metadata": {
        "id": "y8FTiXW5W1ax",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3ffd0d9-5b4f-4b19-c715-f171f5d8c868"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.33.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.6.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fsspec, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 2.14.4\n",
            "    Uninstalling datasets-2.14.4:\n",
            "      Successfully uninstalled datasets-2.14.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
            "sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.37.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.6.0 fsspec-2025.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U datasets --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tTJQ6qiOW5Kp",
      "metadata": {
        "id": "tTJQ6qiOW5Kp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25936b0a-dd6f-4af6-91d6-6a3c27360eb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.37.2\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/__init__.py\n"
          ]
        }
      ],
      "source": [
        "import transformers\n",
        "print(transformers.__version__)\n",
        "print(transformers.__file__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8e99229",
      "metadata": {
        "id": "f8e99229"
      },
      "source": [
        "## ğŸ”¹ Imports and Hyperparameter Grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b700b41",
      "metadata": {
        "id": "9b700b41"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from datetime import datetime\n",
        "import gc\n",
        "import joblib\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from scipy.special import softmax\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import (accuracy_score, precision_recall_fscore_support, roc_auc_score,\n",
        "                             confusion_matrix, ConfusionMatrixDisplay, classification_report,\n",
        "                             roc_curve, auc, f1_score)\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from transformers import (AutoTokenizer, AutoModel, AutoModelForSequenceClassification, TrainingArguments,\n",
        "                          Trainer, EarlyStoppingCallback, set_seed)\n",
        "\n",
        "# Define hyperparameter grid\n",
        "hyperparameter_grid = [\n",
        "    {\"learning_rate\": 5e-5, \"weight_decay\": 0.01},\n",
        "    {\"learning_rate\": 3e-5, \"weight_decay\": 0.01},\n",
        "    {\"learning_rate\": 2e-5, \"weight_decay\": 0.1},\n",
        "    {\"learning_rate\": 2e-5, \"weight_decay\": 0.01},  # baseline\n",
        "    {\"learning_rate\": 1e-5, \"weight_decay\": 0.01},\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6e8c6a3",
      "metadata": {
        "id": "b6e8c6a3"
      },
      "source": [
        "## ğŸ”¹ Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03a71ef2",
      "metadata": {
        "id": "03a71ef2"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_cache(emails, tokenizer_name=\"microsoft/deberta-v3-base\", max_length=320,\n",
        "                       save_path=\"tokenized_emails.pt\", force_retokenize=False):\n",
        "    if Path(save_path).exists() and not force_retokenize:\n",
        "        print(f\"Loading tokenized data from '{save_path}'...\")\n",
        "        return torch.load(save_path)\n",
        "    print(f\"Tokenizing {len(emails)} emails with max_length={max_length}...\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
        "    tokenized = tokenizer(\n",
        "        emails, max_length=max_length, padding=\"max_length\", truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    torch.save(tokenized, save_path)\n",
        "    print(f\"Saved tokenized data to '{save_path}'\")\n",
        "    return tokenized\n",
        "\n",
        "def save_classification_report(report_str, filename):\n",
        "    with open(filename, 'w') as f:\n",
        "        f.write(report_str)\n",
        "    print(f\"Saved classification report to {filename}\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    # eval_pred is now a `EvalPrediction` object with .predictions and .label_ids\n",
        "    logits = eval_pred.predictions[0]\n",
        "    labels = eval_pred.label_ids\n",
        "\n",
        "    # Sanitize logits\n",
        "    logits = np.array(logits, dtype=np.float32)\n",
        "    if not np.isfinite(logits).all():\n",
        "        print(\"Detected NaN or Inf in logits before softmax\")\n",
        "        logits = np.nan_to_num(logits, nan=0.0, posinf=10.0, neginf=-10.0)\n",
        "\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    # Convert logits to probabilities using softmax\n",
        "    probs = softmax(logits, axis=1)[:, 1] if logits.shape[1] > 1 else softmax(logits, axis=1)[:, 0]\n",
        "\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        labels, predictions, average='binary', zero_division=0\n",
        "    )\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "\n",
        "    try:\n",
        "        roc_auc = roc_auc_score(labels, probs)\n",
        "    except ValueError:\n",
        "        roc_auc = float('nan')\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": acc,\n",
        "        \"f1\": f1,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"roc_auc\": roc_auc,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset class\n",
        "class EmailDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.encodings = tokenizer(list(df[\"cleaned text\"]), truncation=True, padding=\"max_length\", max_length=512)\n",
        "        self.features = df[[\"link_count\", \"email length\"]].values\n",
        "        assert np.isfinite(self.features).all(), \"Detected NaN or Inf in input features\"\n",
        "        self.labels = df[\"label\"].values.astype(int)\n",
        "        assert not np.isnan(self.labels).any(), \"NaNs in labels\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item[\"features\"] = torch.tensor(self.features[idx], dtype=torch.float32)\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return item"
      ],
      "metadata": {
        "id": "itgdONA3efPD"
      },
      "id": "itgdONA3efPD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model class\n",
        "class DebertaWithFeatures(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.deberta = AutoModel.from_pretrained(\"microsoft/deberta-v3-base\")\n",
        "        self.config = self.deberta.config\n",
        "        self.config.return_dict = True\n",
        "        self.hidden_size = self.deberta.config.hidden_size\n",
        "        self.feature_proj = nn.Linear(2, 32)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(self.hidden_size + 32, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, features, labels=None):\n",
        "      deberta_output = self.deberta(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "      if self.config.return_dict:\n",
        "          cls_output = deberta_output.last_hidden_state[:, 0]\n",
        "      else:\n",
        "          cls_output = deberta_output[0][:, 0]  # first element of tuple, first token CLS\n",
        "\n",
        "      feature_proj = self.feature_proj(features)\n",
        "      feature_proj = torch.clamp(feature_proj, -10.0, 10.0)\n",
        "      combined = torch.cat((cls_output, feature_proj), dim=1)\n",
        "      logits = self.classifier(combined)\n",
        "\n",
        "      if torch.isnan(logits).any() or torch.isinf(logits).any():\n",
        "        print(\"NaNs in logits at batch\")\n",
        "        print(\"CLS shape:\", cls_output.shape)\n",
        "        print(\"Features shape:\", features.shape)\n",
        "        print(\"Feature values:\", features[0])\n",
        "\n",
        "      loss = None\n",
        "      if labels is not None:\n",
        "          loss_fn = nn.CrossEntropyLoss()\n",
        "          loss = loss_fn(logits, labels)\n",
        "\n",
        "      return {\"loss\": loss, \"logits\": logits, \"labels\": labels}"
      ],
      "metadata": {
        "id": "b_87Cfnse4ZI"
      },
      "id": "b_87Cfnse4ZI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "        return {\n",
        "            \"input_ids\": torch.stack([x[\"input_ids\"] for x in batch]),\n",
        "            \"attention_mask\": torch.stack([x[\"attention_mask\"] for x in batch]),\n",
        "            \"features\": torch.stack([x[\"features\"] for x in batch]),\n",
        "            \"labels\": torch.tensor([int(x[\"labels\"]) for x in batch], dtype=torch.long)\n",
        "        }"
      ],
      "metadata": {
        "id": "nb0Q4juDgIHJ"
      },
      "id": "nb0Q4juDgIHJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "03199218",
      "metadata": {
        "id": "03199218"
      },
      "source": [
        "## ğŸ”¹ Load Dataset and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sWtCvb-YSSlt",
      "metadata": {
        "id": "sWtCvb-YSSlt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "763350ad-f0c4-47bc-bc72-edd163eea9b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "experiment_index = 4  # replace with desired config index\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define a base path in Google Drive to save outputs\n",
        "data_path = '/content/drive/My Drive/Cybersecurity Practicum/'\n",
        "drive_base_path = '/content/drive/My Drive/Cybersecurity Practicum/Custom_CV_phishing_results'\n",
        "Deberta_data_path = '/content/drive/My Drive/Cybersecurity Practicum/Custom_CV_phishing_results/New_Deberta_data'\n",
        "report_path = '/content/drive/My Drive/Cybersecurity Practicum/Custom_CV_phishing_results/New_Deberta_results'\n",
        "report_dir = os.path.join(report_path, f\"config_{experiment_index}\")\n",
        "import os\n",
        "os.makedirs(drive_base_path, exist_ok=True)\n",
        "os.makedirs(Deberta_data_path, exist_ok=True)\n",
        "os.makedirs(report_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e01d255",
      "metadata": {
        "id": "7e01d255",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567,
          "referenced_widgets": [
            "21350ec74f414ca9a6f8d51d2b884b4f",
            "bfa1538731e24554a5682f734bd8c94a",
            "5a6d36be6f6f406da4144a9d6eeadae8",
            "2f53231b1d0a4199aa9b72f2e50040b5",
            "ea0b9baf96804e99affc7698dfa14c87",
            "5fae20d7a1e84c33834e7905e33e4d62",
            "6facd05cb9924ea9a39464cb61411599",
            "69dfc7226cc34c518e17592c5eab6e43",
            "9039cb1ea36d4b9183db2d3f53874fe0",
            "cd729e7eb4384a63b6c0b96261bf7d70",
            "f53c6a21cfdd4c529e54bac94cc0a5b2",
            "11598be60a4444889f33b4653189656d",
            "7194d798c9c14e5a92bdd81fedd3b5de",
            "4fbe1cedad664a1e96b6ea20c597c311",
            "91cb83014730411ea2f300d461246a9f",
            "3b40965eb4ed4ae9a0ec876542f77b71",
            "7431f02b40e5465cabeb10664a01fe96",
            "64ec8940c20641fe933b6cdc2b7a0c5e",
            "b00fdfcccf5147778abe0765a82f8043",
            "e7848c7d33c84f458ef175df3942227d",
            "d35ddab4b55247f1823c7baac4a8017d",
            "3c80fba5d88b4ede9717b7e070d7f40d",
            "c8e01b4b607d48e9ac052ba22429a8a0",
            "ab9b7f4c80a444e08bcd9b4977303c4c",
            "668efabc68fe4783a409560955c5f082",
            "5b569e6df2684f96b14ac724477d07ab",
            "bac3f719b80a497cb9702906926beb2b",
            "7be4b9895f6448429f0fa45cbbd65a12",
            "19c0522094db4e459aeb49d9549b5213",
            "318e13e52bea413ab7bd1c02ce454162",
            "2b6dc5cd4de14de3953aeb83faa2967f",
            "9d9ebcee5603411ba6978f128e75018a",
            "ca0b73660a644cac808877acbf60faf0"
          ]
        },
        "outputId": "72bdbd8a-1989-422d-8e43-4c516a2a369c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running experiment with config: {'learning_rate': 1e-05, 'weight_decay': 0.01}\n",
            "Missing in features:\n",
            " link_count      0\n",
            "email length    0\n",
            "dtype: int64\n",
            "Feature value stats:\n",
            "          link_count  email length\n",
            "count  87792.000000  8.779200e+04\n",
            "mean       3.101911  1.239132e+03\n",
            "std       10.299092  1.498235e+04\n",
            "min        0.000000  9.000000e+00\n",
            "25%        0.000000  2.770000e+02\n",
            "50%        1.000000  5.370000e+02\n",
            "75%        2.000000  1.272250e+03\n",
            "max     1029.000000  4.279447e+06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21350ec74f414ca9a6f8d51d2b884b4f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "11598be60a4444889f33b4653189656d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c8e01b4b607d48e9ac052ba22429a8a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:515: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "config = hyperparameter_grid[experiment_index]\n",
        "print(f\"Running experiment with config: {config}\")\n",
        "\n",
        "df = pd.read_csv(os.path.join(data_path, \"finalized_dataset.csv\"))\n",
        "df[\"cleaned text\"] = df[\"cleaned text\"].astype(str)\n",
        "# Ensure label column is integer type\n",
        "df[\"label\"] = df[\"label\"].astype(int)\n",
        "\n",
        "print(\"Missing in features:\\n\", df[[\"link_count\", \"email length\"]].isna().sum())\n",
        "print(\"Feature value stats:\\n\", df[[\"link_count\", \"email length\"]].describe())\n",
        "\n",
        "# Fix extreme outliers\n",
        "df[\"link_count\"] = df[\"link_count\"].clip(0, 100)\n",
        "df[\"email length\"] = df[\"email length\"].clip(0, 20000)\n",
        "\n",
        "# Split into training (80%) and test (20%) stratified\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df[\"label\"], random_state=42)\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "train_df[[\"link_count\", \"email length\"]] = scaler.fit_transform(train_df[[\"link_count\", \"email length\"]])\n",
        "test_df[[\"link_count\", \"email length\"]] = scaler.transform(test_df[[\"link_count\", \"email length\"]])\n",
        "\n",
        "# Save full train/test split\n",
        "train_df.to_csv(Deberta_data_path + \"/train_full.csv\", index=False)\n",
        "test_df.to_csv(Deberta_data_path + \"/test_holdout.csv\", index=False)\n",
        "\n",
        "# Load Tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-base\")\n",
        "\n",
        "# Stratified K-Fold with HuggingFace Trainer\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "X = train_df.index.values\n",
        "y = train_df[\"label\"].values\n",
        "\n",
        "best_f1 = 0.0\n",
        "best_model_dir = None\n",
        "\n",
        "all_fold_metrics = []"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a28acc5f",
      "metadata": {
        "id": "a28acc5f"
      },
      "source": [
        "## ğŸ”¹ Cross-Validation Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc15756e",
      "metadata": {
        "id": "fc15756e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "287cdd8f-cdb5-4cf9-860b-b7615a1c8242"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Fold 1/5 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Fold 1 already exists, skipping...\n",
            "\n",
            "===== Fold 2/5 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Fold 2 already exists, skipping...\n",
            "\n",
            "===== Fold 3/5 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Fold 3 already exists, skipping...\n",
            "\n",
            "===== Fold 4/5 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Fold 4 already exists, skipping...\n",
            "\n",
            "===== Fold 5/5 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Model on fold 5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjessica-borowy-1\u001b[0m (\u001b[33mjessica-borowy-1-georgia-tech-yellow-jackets\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.20.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250630_011543-0kebu4fp</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jessica-borowy-1-georgia-tech-yellow-jackets/huggingface/runs/0kebu4fp' target=\"_blank\">splendid-shape-23</a></strong> to <a href='https://wandb.ai/jessica-borowy-1-georgia-tech-yellow-jackets/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/jessica-borowy-1-georgia-tech-yellow-jackets/huggingface' target=\"_blank\">https://wandb.ai/jessica-borowy-1-georgia-tech-yellow-jackets/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/jessica-borowy-1-georgia-tech-yellow-jackets/huggingface/runs/0kebu4fp' target=\"_blank\">https://wandb.ai/jessica-borowy-1-georgia-tech-yellow-jackets/huggingface/runs/0kebu4fp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10536' max='10536' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10536/10536 1:37:57, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.011300</td>\n",
              "      <td>0.040024</td>\n",
              "      <td>0.991029</td>\n",
              "      <td>0.991888</td>\n",
              "      <td>0.997281</td>\n",
              "      <td>0.986552</td>\n",
              "      <td>0.999653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.095000</td>\n",
              "      <td>0.029428</td>\n",
              "      <td>0.994589</td>\n",
              "      <td>0.995147</td>\n",
              "      <td>0.992233</td>\n",
              "      <td>0.998079</td>\n",
              "      <td>0.999729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.024374</td>\n",
              "      <td>0.995586</td>\n",
              "      <td>0.996028</td>\n",
              "      <td>0.996538</td>\n",
              "      <td>0.995517</td>\n",
              "      <td>0.999789</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining fold metrics for fold 5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5 F1 Score: 0.9960\n",
            "New best model saved to /content/drive/My Drive/Cybersecurity Practicum/Custom_CV_phishing_results/New_Deberta_results/config_4/best_model_fold_5\n",
            "\n",
            "Classification report for Fold 5 Validation:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Legit     0.9944    0.9957    0.9950      6238\n",
            "       Phish     0.9965    0.9955    0.9960      7808\n",
            "\n",
            "    accuracy                         0.9956     14046\n",
            "   macro avg     0.9955    0.9956    0.9955     14046\n",
            "weighted avg     0.9956    0.9956    0.9956     14046\n",
            "\n",
            "Saved classification report to /content/drive/My Drive/Cybersecurity Practicum/Custom_CV_phishing_results/New_Deberta_results/config_4/fold5_val_classification_report.txt\n"
          ]
        }
      ],
      "source": [
        "k = 5\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):\n",
        "        print(f\"\\n===== Fold {fold}/{k} =====\")\n",
        "\n",
        "        fold_train_df = df.iloc[train_idx].reset_index(drop=True)\n",
        "        os.makedirs(f\"{Deberta_data_path}/fold_{fold}/\", exist_ok=True)\n",
        "        os.makedirs(f\"{Deberta_data_path}/fold_{fold}/\", exist_ok=True)\n",
        "        fold_train_df.to_csv(f\"{Deberta_data_path}/fold_{fold}/train.csv\", index=False)\n",
        "        fold_val_df = df.iloc[val_idx].reset_index(drop=True)\n",
        "        fold_val_df.to_csv(f\"{Deberta_data_path}/fold_{fold}/val.csv\", index=False)\n",
        "\n",
        "        # Sanity checks\n",
        "        assert fold_val_df[\"label\"].notna().all(), f\"NaNs in validation labels for fold {fold}\"\n",
        "        assert fold_train_df[\"label\"].notna().all(), f\"NaNs in training labels for fold {fold}\"\n",
        "        assert set(fold_val_df[\"label\"].unique()).issubset({0, 1}), f\"Unexpected labels in validation set for fold {fold}\"\n",
        "        assert set(fold_train_df[\"label\"].unique()).issubset({0, 1}), f\"Unexpected labels in training set for fold {fold}\"\n",
        "\n",
        "        if len(np.unique(fold_val_df[\"label\"])) < 2:\n",
        "          print(f\"Warning: Fold {fold} validation set has only one class!\")\n",
        "\n",
        "        train_dataset = EmailDataset(fold_train_df)\n",
        "        val_dataset = EmailDataset(fold_val_df)\n",
        "\n",
        "        set_seed(42)\n",
        "        model = DebertaWithFeatures()\n",
        "\n",
        "        fold_output_dir = os.path.join(report_dir, f\"fold{fold}_results\")\n",
        "        if os.path.exists(fold_output_dir):\n",
        "          print(f\"Fold {fold} already exists, skipping...\")\n",
        "          continue\n",
        "\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir=fold_output_dir,\n",
        "            evaluation_strategy=\"epoch\",\n",
        "            save_strategy=\"epoch\",\n",
        "            learning_rate=config[\"learning_rate\"],\n",
        "            per_device_train_batch_size=16,\n",
        "            per_device_eval_batch_size=16,\n",
        "            num_train_epochs=3,\n",
        "            weight_decay=config[\"weight_decay\"],\n",
        "            load_best_model_at_end=True,\n",
        "            metric_for_best_model=\"f1\",\n",
        "            greater_is_better=True,\n",
        "            logging_dir=os.path.join(report_dir, \"logs\"),\n",
        "            logging_steps=10,\n",
        "            fp16=False,\n",
        "            max_grad_norm=1.0,  # Clipping to prevent exploding gradients\n",
        "            gradient_accumulation_steps=1,\n",
        "            overwrite_output_dir=True\n",
        "        )\n",
        "\n",
        "        trainer = Trainer(\n",
        "            model=model,\n",
        "            args=training_args,\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=val_dataset,\n",
        "            compute_metrics=compute_metrics,\n",
        "            callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
        "            data_collator=collate_fn\n",
        "        )\n",
        "\n",
        "        trainer.model.config.return_dict = True\n",
        "\n",
        "        print(f\"Training Model on fold {fold}\")\n",
        "        trainer.train()\n",
        "\n",
        "        print(f\"Obtaining fold metrics for fold {fold}\")\n",
        "        fold_metrics_over_epochs = []\n",
        "        for entry in trainer.state.log_history:\n",
        "            if \"eval_f1\" in entry and \"epoch\" in entry:\n",
        "                fold_metrics_over_epochs.append({\n",
        "                    \"fold\": fold,\n",
        "                    \"epoch\": entry[\"epoch\"],\n",
        "                    \"f1\": entry[\"eval_f1\"],\n",
        "                    \"accuracy\": entry.get(\"eval_accuracy\"),\n",
        "                    \"precision\": entry.get(\"eval_precision\"),\n",
        "                    \"recall\": entry.get(\"eval_recall\"),\n",
        "                })\n",
        "        all_fold_metrics.extend(fold_metrics_over_epochs)\n",
        "\n",
        "        # Extract optimizer info\n",
        "        optimizer_type = type(trainer.optimizer).__name__\n",
        "        optimizer_params = trainer.optimizer.param_groups[0]\n",
        "\n",
        "        learning_rate = optimizer_params.get(\"lr\", \"N/A\")\n",
        "        weight_decay = training_args.weight_decay\n",
        "        betas = optimizer_params.get(\"betas\", (\"N/A\", \"N/A\"))\n",
        "        epsilon = training_args.adam_epsilon if hasattr(training_args, \"adam_epsilon\") else \"N/A\"\n",
        "\n",
        "        # DeBERTa uses CrossEntropyLoss for classification by default\n",
        "        loss_type = \"CrossEntropyLoss\"\n",
        "\n",
        "        # Classification report & confusion matrix for validation set\n",
        "        val_preds = trainer.predict(val_dataset)\n",
        "\n",
        "        # Save misclassified samples\n",
        "        misclassified = fold_val_df.copy()\n",
        "        logits = val_preds.predictions[0]\n",
        "        preds = np.argmax(logits, axis=-1)\n",
        "        probs = torch.nn.functional.softmax(torch.tensor(logits), dim=1).numpy()\n",
        "        misclassified[\"predicted_label\"] = preds\n",
        "        misclassified[\"confidence\"] = probs[np.arange(len(preds)), preds]  # probability of predicted class\n",
        "        misclassified = misclassified[misclassified[\"label\"] != misclassified[\"predicted_label\"]]\n",
        "        os.makedirs(f\"{report_dir}/fold_{fold}\", exist_ok=True)\n",
        "        misclassified.to_csv(f\"{report_dir}/fold_{fold}/misclassified.csv\", index=False)\n",
        "\n",
        "        y_val_true = val_preds.label_ids\n",
        "        f1 = f1_score(y_val_true, preds)\n",
        "        print(f\"Fold {fold} F1 Score: {f1:.4f}\")\n",
        "\n",
        "        if f1 > best_f1:\n",
        "          best_f1 = f1\n",
        "          best_model_dir = os.path.join(report_dir, f\"best_model_fold_{fold}\")\n",
        "          os.makedirs(best_model_dir, exist_ok=True)\n",
        "          torch.save(model.state_dict(), os.path.join(best_model_dir, \"model.pt\"))\n",
        "          tokenizer.save_pretrained(best_model_dir)\n",
        "          joblib.dump(scaler, os.path.join(best_model_dir, \"scaler.pkl\"))\n",
        "          print(f\"New best model saved to {best_model_dir}\")\n",
        "\n",
        "        val_class_report = classification_report(\n",
        "            y_val_true, preds, target_names=[\"Legit\", \"Phish\"], digits=4\n",
        "        )\n",
        "        # Full report\n",
        "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        report_text = f\"\"\"\n",
        "        ==================== EVALUATION REPORT ====================\n",
        "\n",
        "        Timestamp       : {timestamp}\n",
        "        Model           : microsoft/deberta-v3-base\n",
        "        Tokenizer       : microsoft/deberta-v3-base\n",
        "        Token Length    : 512\n",
        "        Max Epochs      : {training_args.num_train_epochs}\n",
        "        Best Metric     : {training_args.metric_for_best_model}\n",
        "\n",
        "        ---------------- Optimizer & Loss Info ----------------\n",
        "        Optimizer       : {optimizer_type}\n",
        "        Learning Rate   : {learning_rate}\n",
        "        Weight Decay    : {weight_decay}\n",
        "        Betas           : {betas}\n",
        "        Epsilon         : {epsilon}\n",
        "        Loss Function   : {loss_type}\n",
        "        ---------------- Classification Report ----------------\n",
        "        {val_class_report}\n",
        "        \"\"\"\n",
        "        print(f\"\\nClassification report for Fold {fold} Validation:\\n{val_class_report}\")\n",
        "\n",
        "        report_path = os.path.join(report_dir, f\"fold{fold}_val_classification_report.txt\")\n",
        "        save_classification_report(report_text, report_path)\n",
        "\n",
        "        cm_val = confusion_matrix(y_val_true, preds)\n",
        "        disp_val = ConfusionMatrixDisplay(cm_val, display_labels=[\"Legit\", \"Phish\"])\n",
        "        disp_val.plot(cmap='Blues')\n",
        "        plt.title(f\"Confusion Matrix - Validation Fold {fold}\")\n",
        "        plt.savefig(os.path.join(report_dir, f\"fold{fold}_val_confusion_matrix.png\"))\n",
        "        plt.close()\n",
        "\n",
        "        # Explicitly delete model, datasets, and predictions\n",
        "        del model\n",
        "        del train_dataset\n",
        "        del val_dataset\n",
        "        del preds\n",
        "        del probs\n",
        "\n",
        "        # Force garbage collection and clear CUDA cache\n",
        "        import gc\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51CY_48hUAlE",
      "metadata": {
        "id": "51CY_48hUAlE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52008a36-404c-4d61-b9c4-900ec790252c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold metrics over time saved to /content/drive/My Drive/Cybersecurity Practicum/Custom_CV_phishing_results/New_Deberta_results/config_4/fold_metrics_over_time.csv\n"
          ]
        }
      ],
      "source": [
        "# Aggregate and save fold metrics over time\n",
        "metrics_df = pd.DataFrame(all_fold_metrics)\n",
        "fold_metrics_path = os.path.join(report_dir, \"fold_metrics_over_time.csv\")\n",
        "metrics_df.to_csv(fold_metrics_path, index=False)\n",
        "print(f\"Fold metrics over time saved to {fold_metrics_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sDrn-pNGUJhC",
      "metadata": {
        "id": "sDrn-pNGUJhC"
      },
      "outputs": [],
      "source": [
        "# Plot F1 and other metrics over epochs per fold\n",
        "# Use a high-contrast palette\n",
        "palette = sns.color_palette(\"colorblind\", n_colors=metrics_df['fold'].nunique())\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.lineplot(data=metrics_df, x=\"epoch\", y=\"f1\", hue=\"fold\", palette=palette, marker=\"o\")\n",
        "plt.title(\"F1 Score over Epochs per Fold\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"F1 Score\")\n",
        "plt.grid(True)\n",
        "plt.legend(title=\"Fold\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(report_dir, \"f1_over_time_across_folds.png\"))\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "g8NR1YrdUTw3",
      "metadata": {
        "id": "g8NR1YrdUTw3"
      },
      "outputs": [],
      "source": [
        "for metric in [\"accuracy\", \"precision\", \"recall\"]:\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        sns.lineplot(data=metrics_df, x=\"epoch\", y=metric, hue=\"fold\", palette=palette, marker=\"o\")\n",
        "        plt.title(f\"{metric.capitalize()} over Epochs per Fold\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(metric.capitalize())\n",
        "        plt.grid(True)\n",
        "        plt.legend(title=\"Fold\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(report_dir, f\"{metric}_over_time_across_folds.png\"))\n",
        "        plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lXfkc_AsUXO3",
      "metadata": {
        "id": "lXfkc_AsUXO3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34c055d8-6ba6-4921-c1a6-24c43eda999e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best model: Fold 5 at epoch 3 with F1=0.9960\n"
          ]
        }
      ],
      "source": [
        "best_row = metrics_df.loc[metrics_df['f1'].idxmax()]\n",
        "best_fold = int(best_row['fold'])\n",
        "best_epoch = int(best_row['epoch'])\n",
        "\n",
        "print(f\"\\nBest model: Fold {best_fold} at epoch {best_epoch} with F1={best_row['f1']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1W_MioJUcRz",
      "metadata": {
        "id": "a1W_MioJUcRz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4ff42df-f456-4a4f-e4a8-1083935a3f47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating on held-out test set using best model\n"
          ]
        }
      ],
      "source": [
        "# Final Test Evaluation\n",
        "print(\"\\nEvaluating on held-out test set using best model\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load best model\n",
        "set_seed(42)\n",
        "best_model = DebertaWithFeatures()\n",
        "best_model_dir = os.path.join(report_dir, f\"best_model_fold_4\")\n",
        "print(f\"Loading best model from {best_model_dir}\")\n",
        "best_model.load_state_dict(torch.load(os.path.join(best_model_dir, \"model.pt\")))\n",
        "best_model.eval()"
      ],
      "metadata": {
        "id": "ptVqLYbOl6f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 937,
          "referenced_widgets": [
            "2bd21faeff5d4b16a22a3fee7bff0860",
            "a817bff94c4c4922a2646267d8aa1a75",
            "60b8a36e6c88423eb8c7b841d2c28ba2",
            "c3be46a366354cc49fbdf329b889ac4b",
            "a96d9b83809d4967a5a598d48857c9e7",
            "427b265ca2f54222b2fd197ee4490deb",
            "343ff835bf8b40648d4d127ff301c8c4",
            "b9048109aa6f473d9f93c5b43dff78c7",
            "54597732e37c40c5b1aa5ee3d5499edd",
            "284b31f50b7949c59886ba67f19d6b56",
            "516fb1b9f9a04f8da486ad45a4418037"
          ]
        },
        "outputId": "809f37f4-e0f2-4270-beac-cb524cb952d8"
      },
      "id": "ptVqLYbOl6f9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2bd21faeff5d4b16a22a3fee7bff0860"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading best model from /content/drive/My Drive/Cybersecurity Practicum/Custom_CV_phishing_results/New_Deberta_results/config_4/best_model_fold_4\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DebertaWithFeatures(\n",
              "  (deberta): DebertaV2Model(\n",
              "    (embeddings): DebertaV2Embeddings(\n",
              "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
              "      (dropout): StableDropout()\n",
              "    )\n",
              "    (encoder): DebertaV2Encoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (rel_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (feature_proj): Linear(in_features=2, out_features=32, bias=True)\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=800, out_features=128, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.2, inplace=False)\n",
              "    (3): Linear(in_features=128, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizer already loaded\n",
        "scaler = joblib.load(os.path.join(best_model_dir, \"scaler.pkl\"))"
      ],
      "metadata": {
        "id": "YrmiB3Fkl_yn"
      },
      "id": "YrmiB3Fkl_yn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "47853810",
      "metadata": {
        "id": "47853810"
      },
      "source": [
        "## ğŸ”¹ Final Evaluation on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da8a1b32",
      "metadata": {
        "id": "da8a1b32"
      },
      "outputs": [],
      "source": [
        "# Prepare test dataset\n",
        "test_dataset = EmailDataset(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ltJUZ0V3U2MX",
      "metadata": {
        "id": "ltJUZ0V3U2MX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9554008-4ae3-46a4-cb0d-2f1321367a99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/accelerate/accelerator.py:450: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Evaluate best model on test set\n",
        "test_training_args = TrainingArguments(\n",
        "    output_dir=os.path.join(report_dir, \"test_results\"),\n",
        "    per_device_eval_batch_size=64,\n",
        "    do_train=False,\n",
        "    do_eval=True,\n",
        "    fp16=True,\n",
        ")\n",
        "test_trainer = Trainer(\n",
        "    model=best_model,\n",
        "    args=test_training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=collate_fn\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wObq2cNAVLcN",
      "metadata": {
        "id": "wObq2cNAVLcN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "ee02e12c-e1bd-4ae5-d9a5-166650690b96"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='275' max='275' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [275/275 01:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjessica-borowy-1\u001b[0m (\u001b[33mjessica-borowy-1-georgia-tech-yellow-jackets\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.20.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250630_155842-hpdh0uac</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jessica-borowy-1-georgia-tech-yellow-jackets/huggingface/runs/hpdh0uac' target=\"_blank\">smart-forest-26</a></strong> to <a href='https://wandb.ai/jessica-borowy-1-georgia-tech-yellow-jackets/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/jessica-borowy-1-georgia-tech-yellow-jackets/huggingface' target=\"_blank\">https://wandb.ai/jessica-borowy-1-georgia-tech-yellow-jackets/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/jessica-borowy-1-georgia-tech-yellow-jackets/huggingface/runs/hpdh0uac' target=\"_blank\">https://wandb.ai/jessica-borowy-1-georgia-tech-yellow-jackets/huggingface/runs/hpdh0uac</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set evaluation metrics:\n",
            "{'eval_loss': 0.00928623415529728, 'eval_accuracy': 0.9977219659433908, 'eval_f1': 0.9979253112033195, 'eval_precision': 0.9983395599833956, 'eval_recall': 0.9975114060555786, 'eval_roc_auc': 0.9999236430311379, 'eval_runtime': 69.0401, 'eval_samples_per_second': 254.33, 'eval_steps_per_second': 3.983}\n"
          ]
        }
      ],
      "source": [
        "test_metrics = test_trainer.evaluate(test_dataset)\n",
        "print(\"\\nTest set evaluation metrics:\")\n",
        "print(test_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "o8PKWQoNVQnz",
      "metadata": {
        "id": "o8PKWQoNVQnz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "0267ce7e-056e-4bee-81c4-54c51e2f6b3f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ],
      "source": [
        "test_preds = test_trainer.predict(test_dataset)\n",
        "\n",
        "# Get full logits\n",
        "logits = test_preds.predictions[0]  # shape: (num_samples, num_classes)\n",
        "y_test_pred = np.argmax(logits, axis=-1)\n",
        "y_test_true = test_preds.label_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jU5Cx-txVT0N",
      "metadata": {
        "id": "jU5Cx-txVT0N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "179c56f3-004b-4a4f-99c5-c108c2ef95af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC Curve graph saved at /content/drive/My Drive/Cybersecurity Practicum/Custom_CV_phishing_results/New_Deberta_results/config_4/roc_curve_test_set.png\n"
          ]
        }
      ],
      "source": [
        "# ROC Curve - Use probabilities for the positive class (class 1)\n",
        "probs = torch.nn.functional.softmax(torch.tensor(logits), dim=1).numpy()[:, 1]\n",
        "fpr, tpr, _ = roc_curve(y_test_true, probs)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Save ROC curve plot\n",
        "roc_path = os.path.join(report_dir, \"roc_curve_test_set.png\")\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {roc_auc:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve - Test Set\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.savefig(roc_path)\n",
        "plt.close()\n",
        "\n",
        "print(f\"ROC Curve graph saved at {roc_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6Hxxw52YVlFe",
      "metadata": {
        "id": "6Hxxw52YVlFe"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test_true, y_test_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Legit\", \"Phish\"])\n",
        "disp.plot(cmap='Blues', xticks_rotation=45)\n",
        "plt.title(\"Confusion Matrix - Phishing Detection\")\n",
        "plt.tight_layout()\n",
        "cm_path1 = os.path.join(report_dir, \"test_confusion_matrix.png\")\n",
        "plt.savefig(cm_path1)\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "I5qaMmGhVpCX",
      "metadata": {
        "id": "I5qaMmGhVpCX"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix (normalized)\n",
        "cm = confusion_matrix(y_test_true, y_test_pred, normalize='true')  # normalize by true labels (rows)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Legit\", \"Phish\"])\n",
        "disp.plot(cmap='Blues', xticks_rotation=45)\n",
        "plt.title(\"Normalized Confusion Matrix - Phishing Detection\")\n",
        "plt.tight_layout()\n",
        "cm_path2 = os.path.join(report_dir, \"test_confusion_matrix_normalized.png\")\n",
        "plt.savefig(cm_path2)\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nK02alhPVu45",
      "metadata": {
        "id": "nK02alhPVu45"
      },
      "outputs": [],
      "source": [
        "test_class_report = classification_report(\n",
        "    y_test_true, y_test_pred, target_names=[\"Legit\", \"Phish\"], digits=4\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QBpVhXJtVxwZ",
      "metadata": {
        "id": "QBpVhXJtVxwZ"
      },
      "outputs": [],
      "source": [
        "# Full report\n",
        "timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "report_text = f\"\"\"\n",
        "==================== EVALUATION REPORT ====================\n",
        "\n",
        "Timestamp       : {timestamp}\n",
        "Model           : microsoft/deberta-v3-base\n",
        "Tokenizer       : microsoft/deberta-v3-base\n",
        "Token Length    : 320\n",
        "Max Epochs      : {training_args.num_train_epochs}\n",
        "Best Metric     : {training_args.metric_for_best_model}\n",
        "\n",
        "---------------- Optimizer & Loss Info ----------------\n",
        "Optimizer       : {optimizer_type}\n",
        "Learning Rate   : {learning_rate}\n",
        "Weight Decay    : {weight_decay}\n",
        "Betas           : {betas}\n",
        "Epsilon         : {epsilon}\n",
        "Loss Function   : {loss_type}\n",
        "\n",
        "---------------- Evaluation Metrics ----------------\n",
        "{json.dumps(test_metrics, indent=4)}\n",
        "\n",
        "ROC Curve visualization saved at: {roc_path}\n",
        "\n",
        "---------------- Classification Report ----------------\n",
        "{test_class_report}\n",
        "\n",
        "Confusion Matrix Saved at: {cm_path1}\n",
        "Normalized Confusion Matrix Saved at: {cm_path2}\n",
        "\n",
        "============================================================\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "r-SESw76V323",
      "metadata": {
        "id": "r-SESw76V323",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80a08079-b836-4b88-bf9e-750e74c50965"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification report for Test Set:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       Legit     0.9970    0.9980    0.9975      7915\n",
            "       Phish     0.9983    0.9975    0.9979      9644\n",
            "\n",
            "    accuracy                         0.9977     17559\n",
            "   macro avg     0.9977    0.9977    0.9977     17559\n",
            "weighted avg     0.9977    0.9977    0.9977     17559\n",
            "\n",
            "Saved classification report to /content/drive/My Drive/Cybersecurity Practicum/Custom_CV_phishing_results/New_Deberta_results/config_4/test_set_classification_report.txt\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nClassification report for Test Set:\\n\", test_class_report)\n",
        "test_report_path = os.path.join(report_dir, \"test_set_classification_report.txt\")\n",
        "save_classification_report(report_text, test_report_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "21350ec74f414ca9a6f8d51d2b884b4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bfa1538731e24554a5682f734bd8c94a",
              "IPY_MODEL_5a6d36be6f6f406da4144a9d6eeadae8",
              "IPY_MODEL_2f53231b1d0a4199aa9b72f2e50040b5"
            ],
            "layout": "IPY_MODEL_ea0b9baf96804e99affc7698dfa14c87"
          }
        },
        "bfa1538731e24554a5682f734bd8c94a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fae20d7a1e84c33834e7905e33e4d62",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6facd05cb9924ea9a39464cb61411599",
            "value": "tokenizer_config.json:â€‡100%"
          }
        },
        "5a6d36be6f6f406da4144a9d6eeadae8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69dfc7226cc34c518e17592c5eab6e43",
            "max": 52,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9039cb1ea36d4b9183db2d3f53874fe0",
            "value": 52
          }
        },
        "2f53231b1d0a4199aa9b72f2e50040b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd729e7eb4384a63b6c0b96261bf7d70",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f53c6a21cfdd4c529e54bac94cc0a5b2",
            "value": "â€‡52.0/52.0â€‡[00:00&lt;00:00,â€‡6.23kB/s]"
          }
        },
        "ea0b9baf96804e99affc7698dfa14c87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fae20d7a1e84c33834e7905e33e4d62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6facd05cb9924ea9a39464cb61411599": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69dfc7226cc34c518e17592c5eab6e43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9039cb1ea36d4b9183db2d3f53874fe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cd729e7eb4384a63b6c0b96261bf7d70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f53c6a21cfdd4c529e54bac94cc0a5b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11598be60a4444889f33b4653189656d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7194d798c9c14e5a92bdd81fedd3b5de",
              "IPY_MODEL_4fbe1cedad664a1e96b6ea20c597c311",
              "IPY_MODEL_91cb83014730411ea2f300d461246a9f"
            ],
            "layout": "IPY_MODEL_3b40965eb4ed4ae9a0ec876542f77b71"
          }
        },
        "7194d798c9c14e5a92bdd81fedd3b5de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7431f02b40e5465cabeb10664a01fe96",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_64ec8940c20641fe933b6cdc2b7a0c5e",
            "value": "config.json:â€‡100%"
          }
        },
        "4fbe1cedad664a1e96b6ea20c597c311": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b00fdfcccf5147778abe0765a82f8043",
            "max": 579,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7848c7d33c84f458ef175df3942227d",
            "value": 579
          }
        },
        "91cb83014730411ea2f300d461246a9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d35ddab4b55247f1823c7baac4a8017d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3c80fba5d88b4ede9717b7e070d7f40d",
            "value": "â€‡579/579â€‡[00:00&lt;00:00,â€‡75.6kB/s]"
          }
        },
        "3b40965eb4ed4ae9a0ec876542f77b71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7431f02b40e5465cabeb10664a01fe96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64ec8940c20641fe933b6cdc2b7a0c5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b00fdfcccf5147778abe0765a82f8043": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7848c7d33c84f458ef175df3942227d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d35ddab4b55247f1823c7baac4a8017d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c80fba5d88b4ede9717b7e070d7f40d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8e01b4b607d48e9ac052ba22429a8a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab9b7f4c80a444e08bcd9b4977303c4c",
              "IPY_MODEL_668efabc68fe4783a409560955c5f082",
              "IPY_MODEL_5b569e6df2684f96b14ac724477d07ab"
            ],
            "layout": "IPY_MODEL_bac3f719b80a497cb9702906926beb2b"
          }
        },
        "ab9b7f4c80a444e08bcd9b4977303c4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7be4b9895f6448429f0fa45cbbd65a12",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_19c0522094db4e459aeb49d9549b5213",
            "value": "spm.model:â€‡100%"
          }
        },
        "668efabc68fe4783a409560955c5f082": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_318e13e52bea413ab7bd1c02ce454162",
            "max": 2464616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2b6dc5cd4de14de3953aeb83faa2967f",
            "value": 2464616
          }
        },
        "5b569e6df2684f96b14ac724477d07ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d9ebcee5603411ba6978f128e75018a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ca0b73660a644cac808877acbf60faf0",
            "value": "â€‡2.46M/2.46Mâ€‡[00:00&lt;00:00,â€‡31.9MB/s]"
          }
        },
        "bac3f719b80a497cb9702906926beb2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7be4b9895f6448429f0fa45cbbd65a12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19c0522094db4e459aeb49d9549b5213": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "318e13e52bea413ab7bd1c02ce454162": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b6dc5cd4de14de3953aeb83faa2967f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d9ebcee5603411ba6978f128e75018a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca0b73660a644cac808877acbf60faf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2bd21faeff5d4b16a22a3fee7bff0860": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a817bff94c4c4922a2646267d8aa1a75",
              "IPY_MODEL_60b8a36e6c88423eb8c7b841d2c28ba2",
              "IPY_MODEL_c3be46a366354cc49fbdf329b889ac4b"
            ],
            "layout": "IPY_MODEL_a96d9b83809d4967a5a598d48857c9e7"
          }
        },
        "a817bff94c4c4922a2646267d8aa1a75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_427b265ca2f54222b2fd197ee4490deb",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_343ff835bf8b40648d4d127ff301c8c4",
            "value": "pytorch_model.bin:â€‡100%"
          }
        },
        "60b8a36e6c88423eb8c7b841d2c28ba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9048109aa6f473d9f93c5b43dff78c7",
            "max": 371146213,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_54597732e37c40c5b1aa5ee3d5499edd",
            "value": 371146213
          }
        },
        "c3be46a366354cc49fbdf329b889ac4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_284b31f50b7949c59886ba67f19d6b56",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_516fb1b9f9a04f8da486ad45a4418037",
            "value": "â€‡371M/371Mâ€‡[00:01&lt;00:00,â€‡244MB/s]"
          }
        },
        "a96d9b83809d4967a5a598d48857c9e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "427b265ca2f54222b2fd197ee4490deb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "343ff835bf8b40648d4d127ff301c8c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9048109aa6f473d9f93c5b43dff78c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54597732e37c40c5b1aa5ee3d5499edd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "284b31f50b7949c59886ba67f19d6b56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "516fb1b9f9a04f8da486ad45a4418037": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}